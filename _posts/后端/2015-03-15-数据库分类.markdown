---
layout: post
category: 后端
---

> 数据库的种类很多，sql的与非sql的。像阿里云上就有十多个数据库，该如何选择呢

# 关系型数据库
阿里云上的RDS都属于关系型的数据库，包含有mysql，sql server等等

## 优点
满足ACID原则，强事务性

## 缺点
要完全满足ACID，则只能单机中实现，这会导致数据量增长有限，当数据量在千万级时就已经很吃力了

## 场景
1. 要求可靠，银行系统，一分钱都不能坏。
2. 要求一致性，踩楼活动的楼层数，快速写同时楼层数要按序增加，不重复。

# 缓存数据库
阿里云上的memcache和redis都属于缓存数据库

## 优点
由于数据完全在内存上，所以速度非常快

## 缺点
1. 数据不可靠，掉电后可能会丢失一小部分数据
2. 数据没有一致性，不要考虑事务性了

## 场景
1. 要求快，但不要求数据能放很多的场景。关系型数据库的热数据存储区，将大部分的热数据放在cache上，只能很少使用的冷数据库才放在数据库上。这样能满足绝大部分用户的快速读的请求。
2. 要求快，但不要求数据可靠的场景。session。

# 分布式非结构化存储数据库
非结构化数据，像音乐，图片，视频，这类缺少结构化的数据。阿里云提供的是OSS存储服务，也有做得好的七牛，又拍云这类服务商。开源的有hdfs。

## 优点
读写量大，数据量大

## 缺点
无事务性，只能存非结构化数据。

## 场景
音乐，图片，视频，静态文件等非结构化数据


# 分布式结构化存储数据库
分布式结构化存储数据库，要求能存放TB级的结构化数据，而且支持快速的增删改查的操作，对事务性的要求不高，而且增删改查操作都是在毫秒级类完成的。阿里云上分别有DRDS，mongodb和TableStore。开源的有hbase。

## DRDS
将单机数据库扩展多机数据库，通过数据的sharding来将数据切分到多个表上。例如用户表，就是以用户ID为key，哈希到多台mysql数据库上。DRDS的优点是能存储数据量大，并保持了单表中的事务性，跨表操作中只支持最终的一致性。缺点是schema比较死。

适合在需要最终一致性的大数据场景，读写量少，例如电商订单信息。

## Mongodb
仍然是数据sharding分布在多个表上，优点是，数据量大，schema灵活，可以动态变化，而且数据类型支持嵌套对象或数组，读取写入速度非常快。缺点是一致性差，经常看到有用户抱怨丢数据。

适合在schema灵活的大数据场景，读写量多，例如用户个人信息。

## TableStore
与mongodb类似，不过听说比mongodb要更靠，但是阿里的私有数据库类型，生态不太好呀，不推荐使用。 

# 分布式计算数据库
分布式计算数据库，要求能存放TB/PB级的结构化数据，数据只能增加，不能删除或修改，对全量数据分析比DRDS，mongodb等相比非常快，不过仍然也要在秒级类完成的。阿里云上的ODPS。开源的有hadoop,hive,storm,spark等等。

## Map-Reduce
将分布式计算抽象为map-reduce两个操作，然后让开发者编写这两步的接口即可实现分布式计算。优点是适用范围广，缺点每次都要重复发明count(\*)，max(\*)等的操作。开源的实现有hadoop，阿里云上的实现为E-MapReduce

## sql的分布式计算
将原来熟知的sql计算解析为一系列的map-reduce操作，然后让map-reduce操作来执行，从而实现了输入原来简单的sql运算就能达到分布式计算的目的。开源的实现有hive，阿里云上的实现为odps。

## 分布式流计算
由于基于map-reduce的分布式计算都是批处理任务，实时性比较差。然后发明了让数据流过分布式机器，而不是机器读取分布式数据的方法，实现了分布式的增量计算。开源的实现有storm，阿里云上的实现为odps。

## 统一分布式计算
由于hadoop的难用，hive的低效，storm的增量计算适用范围有限，导致了一个新的分布式计算框架出现，spark。spark有以下的几点优化：

1. 使用内存做中间结果缓存。借鉴了storm的优点，避免了hadoop不断读写磁盘造成严重的性能问题。
2. RDD优化并行作业流水线。各个分布式任务之间的依赖在执行前就可以确定下来，使得spark知道如何加快流水线的速度，避免hadoop在reduce时需要盲目等待前面所有map的完成。
3. 将数据切片分成单个batch。借鉴了storm的流计算有点，避免了hadoop只能做批处理的问题。

spark借鉴了多个分布式计算框架的优点，从而实现了一个统一的同时支持实时计算，离线计算，图计算和机器学习计算的框架。阿里云上对应的实现为E-MapReduce。

## 场景
适合做大数据分析。
1. 日志服务，详细分析一个月内的某接口的调用情况
2. 网页分析服务，详细分析每天的页面访问量，跳出率等数据。
3. 数据挖掘，像聚类算法，pageRank算法。
4. PV,UV,排行榜等统计数据的实时维护。



